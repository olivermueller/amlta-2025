{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJrKCbjZsqpo"
   },
   "source": [
    "# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-DU0hkyVyPi"
   },
   "source": [
    "# <font color=\"#003660\">Session 1: Introduction to Natural Language Processing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhy42GjRV3ON"
   },
   "source": [
    "# <font color=\"#003660\">Notebook 1: Document Classification</font>\n",
    "\n",
    "<center><br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/dag.png\"/><br></center>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<div>\n",
    "    <font color=\"#085986\"><b>By the end of this lesson, you will be able to...</b><br><br>\n",
    "        ... transform raw text into a term-document matrix, <br>\n",
    "        ... train a binary classifier on the term-document matrix, and <br> ... and compete in a Kaggle competition.\n",
    "    </font>\n",
    "</div>\n",
    "</center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6vVpwIFsqps"
   },
   "source": [
    "# Import packages\n",
    "\n",
    "As always, we first need to load a number of required Python packages:\n",
    "- `pandas` provides high-performance, easy-to-use data structures and data analysis tools.\n",
    "- `spacy` offers industrial-strength natural language processing.\n",
    "- `sklearn` is the de-facto standard machine learning package in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMrhkr83sqpt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZd82t53sqpu"
   },
   "source": [
    "# Load documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsrCafxksqpv"
   },
   "source": [
    "Load wine reviews (Source: https://www.kaggle.com/datasets/zynicide/wine-reviews) from a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"https://raw.githubusercontent.com/olivermueller/amlta-2025/main/Session_01/winemag-data-130k-v2.csv\")\n",
    "corpus.rename(columns = {'Unnamed: 0':'index'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666269247369,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -120
    },
    "id": "bMzZ9re_yY5K",
    "outputId": "7f61bd27-df93-4057-eff7-f63684e6fc72"
   },
   "outputs": [],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1666269247689,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -120
    },
    "id": "7NsIQrLiSEak",
    "outputId": "274be739-6a25-448e-a0d2-8702bb598576"
   },
   "outputs": [],
   "source": [
    "corpus.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1v8oiPAcsqpx"
   },
   "source": [
    "# Preprocess documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[\"verygood\"] = 0\n",
    "corpus.loc[corpus['points'] > 90, 'verygood'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7psnR5cmQLBx"
   },
   "source": [
    "Split data into training, validation, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSObnTaWdgdM"
   },
   "outputs": [],
   "source": [
    "training = corpus.iloc[0:80000,]\n",
    "validation = corpus.iloc[80000:100000,]\n",
    "test = corpus.iloc[100000:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666269440366,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -120
    },
    "id": "m05pjMr8Rvxs",
    "outputId": "aeed0594-90ff-4fe2-9362-462b8874376f"
   },
   "outputs": [],
   "source": [
    "print(training.shape)\n",
    "print(validation.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSrHVdoZsqpy"
   },
   "source": [
    "Perform standard NLP preprocessing steps on the training set using spaCy. spaCy is an open-source library for Natural Language Processing (NLP) in Python. It helps you build NLP applications that process and understand large volumes of unstructured text. One of the main features of spaCy are linguistic annotations that give you insights into a textâ€™s grammatical structure (e.g., word order, types of words, parts of speech, grammatical roles and relations).\n",
    "\n",
    "At the center of spaCy is the processing pipeline, an object which is usually called `nlp`. The pipeline is build on top of a language-specific machine learning model and a set of handcrafted rules.\n",
    "\n",
    "The pipeline contains different components, each specialized for a specific NLP task.\n",
    "\n",
    "[More...](https://spacy.io/usage/spacy-101#whats-spacy)\n",
    "\n",
    "<center><br><img src=\"\n",
    "https://d33wubrfki0l68.cloudfront.net/3ad0582d97663a1272ffc4ccf09f1c5b335b17e9/7f49c/pipeline-fde48da9b43661abcdf62ab70a546d71.svg\"/><br></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sh4KVmP6sqpy"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\", \"parser\", \"textcat\"])\n",
    "\n",
    "def spacy_prep_df(df, text_col=\"description\", batch_size=1000, n_process=4):\n",
    "    texts = (str(x) if pd.notna(x) and x else \"\" for x in df[text_col].values)\n",
    "    results = []\n",
    "    with nlp.select_pipes(disable=[]):\n",
    "        for doc in nlp.pipe(texts, batch_size=batch_size, n_process=n_process):\n",
    "            if doc.text:\n",
    "                toks = [t.lemma_.lower() for t in doc if t.is_alpha and not t.is_stop]\n",
    "                results.append(\" \".join(toks))\n",
    "            else:\n",
    "                results.append(\"\")\n",
    "    out = df.copy()\n",
    "    out[text_col + \"_prep\"] = results\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4rKCZRs9tlj"
   },
   "outputs": [],
   "source": [
    "training = spacy_prep_df(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Tothp_Ssqpz"
   },
   "source": [
    "Display the first couple of lines of the preprocessed descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1666270637484,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -120
    },
    "id": "UyLoiearsqpz",
    "outputId": "c1a8fffa-cc0b-4120-b14a-b1784806d981"
   },
   "outputs": [],
   "source": [
    "training[\"description_prep\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYQppmeBQUtX"
   },
   "source": [
    "# Vectorize documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAXDnM1Hsqp1"
   },
   "source": [
    "Vectorization is the process of turning a collection of text documents into numerical feature vectors.\n",
    "\n",
    "We will use the **Bag of Words (BoW)** model for vectorization. In the BoW model, a corpus of documents is represented by a matrix with one row per document and one column per word occurring in the corpus. The cell values will either be simple frequency counts (How often does a word appear in a document?), or the term frequency (tf) times the inverse document frequency (idf) of a term. The idea of tf-idf is to scale down the impact of words that occur very frequently in a given corpus and that are therefore less informative than features that occur only in a small fraction of the corpus. Note that the BoW model completely ignores information about the position and sequences of the words in the document.\n",
    "\n",
    "In `sklearn`, the [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) creates a term-document matrix with (normalized) term frequencies and the [`TfIdfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer) creates a term-document matrix with tf-idf weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbeTq9S9sqp1"
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(min_df=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06DEGrExsqp1"
   },
   "source": [
    "Apply the CountVectorizer object to the review texts of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AemriJOAsqp1"
   },
   "outputs": [],
   "source": [
    "X_training = count_vect.fit_transform(training[\"description_prep\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OV17A_2sqp2"
   },
   "source": [
    "Display an extract of the generated term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1666270941802,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -120
    },
    "id": "vLq7fYBy3J2q",
    "outputId": "031fef17-71e1-4d99-c36a-dd48939fa6ed"
   },
   "outputs": [],
   "source": [
    "X_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1666270948540,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -120
    },
    "id": "ANQd_dVlsqp2",
    "outputId": "639aa9c4-08fc-46ab-a637-2ad950e9b8b3"
   },
   "outputs": [],
   "source": [
    "X_training[0:20,0:20].todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QTlJ4BDsqp3"
   },
   "source": [
    "Store the labels that we want to predict in a separate variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1666271013159,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -120
    },
    "id": "gUpaU5Pgsqp3",
    "outputId": "245d8d8c-e92f-4cc8-d350-eb81413ab6b9"
   },
   "outputs": [],
   "source": [
    "y_training = training[\"verygood\"]\n",
    "y_training.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biwWaNjNsqp4"
   },
   "source": [
    "# Train classifier on training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTHaUsAosqp4"
   },
   "source": [
    "Fit a logistic regression classification with the term-document matrix as the features and the wine quality (i.e., `verygood` variable) as the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZkAh7oesqp4"
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000).fit(X_training, y_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuAVWgC8sqp4"
   },
   "source": [
    "Test whether classifier is working by predicting the quality of a short fake review. We apply the same NLP preprocessing steps and reuse the `count_vect` object to generate features in the same way as we did for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrjU4Uj4-jpx"
   },
   "outputs": [],
   "source": [
    "doc_new = {'description': ['This is a spectacular, magnificent, and majestic wine. Awesome!']}\n",
    "doc_new_df = pd.DataFrame.from_dict(doc_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666271286359,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -120
    },
    "id": "_B16iOiWsqp5",
    "outputId": "977e054f-0750-4753-d04f-2d9aa4dfb19c"
   },
   "outputs": [],
   "source": [
    "doc_new_df_prep = spacy_prep_df(doc_new_df)\n",
    "doc_new_df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666271286359,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -120
    },
    "id": "6sD7SeyD4nig",
    "outputId": "0de40203-fd29-4095-80dd-03d5bbbeacc2"
   },
   "outputs": [],
   "source": [
    "X_new = count_vect.transform(doc_new_df_prep[\"description_prep\"])\n",
    "predicted = clf.predict(X_new)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6zZzlq4sqp5"
   },
   "source": [
    "Instead of predicting binary labels, we can also predict probabilities of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1666271289647,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -120
    },
    "id": "Ks6yRPyEsqp5",
    "outputId": "5c9b30c2-c5f8-48d4-c53a-7c7bd4e20e21"
   },
   "outputs": [],
   "source": [
    "predicted_prob = clf.predict_proba(X_new)\n",
    "print(clf.classes_)\n",
    "print(predicted_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "663LU5XQsqp5"
   },
   "source": [
    "# Evaluate accuracy on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8-z8rqVsqp6"
   },
   "source": [
    "Before trying to predict the labels for the official test set, we evaluate the predictive accurcay of our model on the validation set. Again, we apply the same NLP preprocessing steps, reuse the `count_vect` object, and store `X` and `y` in separate data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCZDzJOR51SZ"
   },
   "outputs": [],
   "source": [
    "validation = spacy_prep_df(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiUIhoK0sqp6"
   },
   "outputs": [],
   "source": [
    "X_validation = count_vect.transform(validation[\"description_prep\"])\n",
    "y_validation = validation[\"verygood\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4upAshmAsqp6"
   },
   "source": [
    "Call the predict function of our model with the validation data and calculate precision, recall and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1666271420302,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -120
    },
    "id": "3Ngkprkgsqp6",
    "outputId": "2713b37d-c8e3-4c95-f9ee-39e2eef82b4f"
   },
   "outputs": [],
   "source": [
    "predictions_validation = clf.predict(X_validation)\n",
    "print(metrics.classification_report(y_validation, predictions_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOCv-dHNsqp6"
   },
   "source": [
    "# Interpret model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oB06C4vFsqp7"
   },
   "source": [
    "Logistic regression is typically not the most accurate classification model, but one big advantage is that it can be interpreted by looking at the coefficients of the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOHsVlNGsqp7"
   },
   "outputs": [],
   "source": [
    "coeffs = clf.coef_[0].tolist()\n",
    "words = count_vect.get_feature_names_out()\n",
    "words_with_coeffs = pd.DataFrame(coeffs, words, columns=[\"coeff\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaHsYC1xsqp7"
   },
   "source": [
    "These are the words with the most *negative* impact.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1666271501133,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -120
    },
    "id": "uc6X4kaFsqp7",
    "outputId": "cc0ded9c-0c54-4958-e6eb-d4a2345780d3"
   },
   "outputs": [],
   "source": [
    "words_with_coeffs.sort_values(\"coeff\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xo2Zz0qrsqp8"
   },
   "source": [
    "And these are the words with the most *positive* impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1666271540487,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -120
    },
    "id": "FBYjvIJnsqp8",
    "outputId": "5d850670-4b10-424b-d12c-24364131d792"
   },
   "outputs": [],
   "source": [
    "words_with_coeffs.sort_values(\"coeff\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EK-kUHvqUT7H"
   },
   "source": [
    "# Make predictions on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOAiyw6_5ZJn"
   },
   "source": [
    "Preprocess and vectorize the review texts of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljCV8CjF5m-B"
   },
   "outputs": [],
   "source": [
    "test = spacy_prep_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKxkVjlsUXCQ"
   },
   "outputs": [],
   "source": [
    "X_test = count_vect.transform(test[\"description_prep\"])\n",
    "predictions_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnUWSu8N5oZN"
   },
   "source": [
    "Create a dataframe with the indices and predictions and save it as a CSV file (which we can upload to Kaggle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dTBW2SnMUkjm"
   },
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'index': test[\"index\"],\n",
    "                              'verygood': predictions_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666271767446,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -120
    },
    "id": "VKwZ8MIcVAjl",
    "outputId": "7b430a7d-e926-4506-9b38-4fe94f1f658f"
   },
   "outputs": [],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzQ2NzHyVvGB"
   },
   "outputs": [],
   "source": [
    "my_submission.to_csv(\"my_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "amlta2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
