{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJrKCbjZsqpo"
   },
   "source": [
    "# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-DU0hkyVyPi"
   },
   "source": [
    "# <font color=\"#003660\">Session 1: Document Classification/Regression with Neural Networks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhy42GjRV3ON"
   },
   "source": [
    "# <font color=\"#003660\">Notebook 6: Long-Short Term Memory (LSTM) Networks with Word Embeddings as Features</font>\n",
    "\n",
    "<center><br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/dag.png\"/><br></center>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<div>\n",
    "    <font color=\"#085986\"><b>By the end of this lesson, you ...</b><br><br>\n",
    "        ... understand the logic behind recurrent neural networks, especially LSTMs. and <br>\n",
    "        ... are able to train a LSTM with word embeddings as features.\n",
    "    </font>\n",
    "</div>\n",
    "</center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hr1lI3joctE6"
   },
   "source": [
    "# What are Recurrent Neural Networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lx6TSeClcvWb"
   },
   "source": [
    "## Simple Recurrent Neural Network (RNN)\n",
    "\n",
    "A RNN processes sequences by iterating through the sequence elements and maintaining a *state* containing information relative to what it has seen so far. In effect, a RNN layer is a neural network layer with an internal loop, as shown in the figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNlB5mtDdLzn"
   },
   "source": [
    "<br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/rnn1.png\"/><br>\n",
    "<center>Source: Chollet (2021)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOobrDD2dMBz"
   },
   "source": [
    "The figure below shows a simple RNN unrolled over time. As can be seen from the figure the output of a layer is a combination of\n",
    "\n",
    "1. its direct data input (`input_t`),\n",
    "2. the layer's state from the previous timestep (`state_t`), and\n",
    "3. a bias term (`bo`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qn6fuh8HdmTo"
   },
   "source": [
    "<br><img width=700 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/rnn2.png\"/><br>\n",
    "\n",
    "<center>Source: Chollet (2021)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrYClhKAduA3"
   },
   "source": [
    "## Long-Short Term Memory (LSTM) Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQny-Crkd0cJ"
   },
   "source": [
    "Compared to a simple RNN layer, a LSTM layer contains one central innovation: A *carry track* that allows to carry over information over time from any previous timestep to the current timestep. Consequently, the output of a layer is a combination of\n",
    "\n",
    "\n",
    "\n",
    "1. its direct data input (`input_t`),\n",
    "2. the layer's state from the previous timestep (`state_t`),\n",
    "3. the input from the carry track (`c_t`), and\n",
    "4. a bias term (`bo`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlZU3v9xd_ia"
   },
   "source": [
    "<br><img width=700 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/lstm.png\"/><br>\n",
    "<center>Source: Chollet (2021)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VpSWKNzXDbv"
   },
   "source": [
    "## Comparing RNNs with MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmKWTO8DXTAq"
   },
   "source": [
    "Andrej Karpathy's legendary blog post \"The Unreasonable Effectiveness of Recurrent Neural Networks\" contains a very informative comparison of RNNs with traditional neural networks: http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6vVpwIFsqps"
   },
   "source": [
    "# Import packages\n",
    "\n",
    "As always, we first need to load a number of required Python packages:\n",
    "- `pandas` provides high-performance, easy-to-use data structures and data analysis tools.\n",
    "- `numpy` is a library adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n",
    "- `sklearn` is a free software machine learning library for the Python programming language.\n",
    "- `tensorflow` is an end-to-end open source platform for machine learning, especially deep learning.\n",
    "- `matplotlib` is a plotting library for the Python programming language and its numerical mathematics extension NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mMrhkr83sqpt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cT264vl78Zo"
   },
   "source": [
    "Check if we are running on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RHONHA667__1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZd82t53sqpu"
   },
   "source": [
    "# Load documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load wine reviews (Source: https://www.kaggle.com/datasets/zynicide/wine-reviews) from a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"https://raw.githubusercontent.com/olivermueller/amlta-2025/main/Session_01/winemag-data-130k-v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CureExnsIS-p"
   },
   "source": [
    "Split data into three sets: training, validation, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BBpPCg5zILlu"
   },
   "outputs": [],
   "source": [
    "training = corpus.iloc[0:80000,].sample(n=10000) # sample to speed up training\n",
    "validation = corpus.iloc[80000:100000,]\n",
    "test = corpus.iloc[100000:,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5Mygm5yIYnh"
   },
   "source": [
    "For each dataset, store features and targets in separate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "18PF5d6ZIN-U"
   },
   "outputs": [],
   "source": [
    "train_corpus_features = training[[\"description\"]]\n",
    "train_corpus_target = training[[\"points\"]]\n",
    "val_corpus_features = validation[[\"description\"]]\n",
    "val_corpus_target = validation[[\"points\"]]\n",
    "test_corpus_features = test[[\"description\"]]\n",
    "test_corpus_target = test[[\"points\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvhh11WuIeyk"
   },
   "source": [
    "Create [TensorFlow `Datasets`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) from the Pandas Dataframes. The use of TensorFlow Datasets follows a common pattern:\n",
    "\n",
    "1.   Create a dataset from raw data (e.g., a Pandas dataframe, a CSV file, multiple text files).\n",
    "2.   Apply transformations to preprocess the data in the dataset (e.g., vectorize text data).\n",
    "3. Iterate over the dataset and process its elements. Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory.\n",
    "\n",
    "Here, we use the `from_tensor_slices` constructor to create datasets from dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QOOszgPrQVVw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 17:45:00.114847: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2025-10-06 17:45:00.114992: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-10-06 17:45:00.115006: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-10-06 17:45:00.115190: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-10-06 17:45:00.115341: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((tf.cast(train_corpus_features.values, tf.string),\n",
    "                                               tf.cast(train_corpus_target.values, tf.int32)))\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((tf.cast(val_corpus_features.values, tf.string),\n",
    "                                             tf.cast(val_corpus_target.values, tf.int32)))\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((tf.cast(test_corpus_features.values, tf.string),\n",
    "                                              tf.cast(test_corpus_target.values, tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXbjrq6NJ1Qk"
   },
   "source": [
    "Display some stats and examples from the created datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "j9LXPIY-XxDH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (1,)\n",
      "inputs.dtype: <dtype: 'string'>\n",
      "targets.shape: (1,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "===\n",
      "inputs[0]: tf.Tensor(b\"There's a salinity to this wine, which is grown to the west of Gilroy on the lower foothills of the Santa Cruz Mountains. Aromas are brackish and suggest sweet lemons, while the palate offers apples, squeezed citrus and a waxy character.\", shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor(84, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"===\")\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uwh4TWJbVFY9"
   },
   "source": [
    "# Vectorize documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rM7gEBL8KHzg"
   },
   "source": [
    "We will now use [TensorFlow's `TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) function to transform raw texts into numerical vectors. Again, we map unique words to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oyJW-JetIN2w"
   },
   "outputs": [],
   "source": [
    "max_tokens = 10000\n",
    "max_length = 100\n",
    "\n",
    "text_vectorization = TextVectorization(\n",
    "    max_tokens = max_tokens,\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length = max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4ElfvWtKj0Q"
   },
   "source": [
    "Some apects of the `TextVectorization` function (e.g., the size and contents of the vocabulary) have to be fit using training data, which can be done with the `adapt` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "s6xCAUAOMdYH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 17:45:00.683341: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "train_ds_features_only = train_ds.map(lambda x, y: x)\n",
    "text_vectorization.adapt(train_ds_features_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkQu4KlNLftU"
   },
   "source": [
    "Show the vocabulary that our vectorizer knows after being fit to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Dn0lt-7CRaCq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'and', 'the', 'a', 'of', 'with', 'this', 'is', 'wine']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization.get_vocabulary()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjeZpApaLvyx"
   },
   "source": [
    "Next, we apply our `text_vectorization` function to all three datasets. This corresponds to step 2 mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jHGn2peqMYuP"
   },
   "outputs": [],
   "source": [
    "vectorized_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls = 4)\n",
    "\n",
    "vectorized_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls = 4)\n",
    "\n",
    "vectorized_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_WzVu2WMEn-"
   },
   "source": [
    "Show results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0etTA2eAUB6G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (1, 100)\n",
      "inputs.dtype: <dtype: 'int64'>\n",
      "targets.shape: (1,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "===\n",
      "inputs[0]: tf.Tensor(\n",
      "[ 125    4 2811   12    7    9  146    8  652   12    3 2595    5    1\n",
      "   15    3 3733 3115    5    3 1123 4413 2045   17   29    1    2  514\n",
      "   51 1132   57    3   18   52  479 2796   58    2    4 1217   83    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0], shape=(100,), dtype=int64)\n",
      "targets[0]: tf.Tensor(84, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in vectorized_train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"===\")\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9QH9PcrSa7J"
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_K1l5L-MQ7z"
   },
   "source": [
    "We are now ready to specify a neural network and feed it with the vectroized datasets. For convenience, we define a custome function `get_model` which defines the network architecture, creates a model from it, and compiles this model (by defining, e.g., an otpimizer and loss function).\n",
    "\n",
    "Instead of averaging or flattening the outputs of the embedding layer, a RNN/LSTM layer can directly process its 2D output (i.e., it takes a sequence of vectors as input instead of a single vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMB14gBYSblz"
   },
   "outputs": [],
   "source": [
    "def get_model(hidden_dim=32):\n",
    "    inputs = keras.Input(shape=(max_length,), dtype=\"int64\")\n",
    "    embedded = layers.Embedding(input_dim=max_tokens, output_dim=300, mask_zero=True)(inputs)\n",
    "    hidden1 = layers.LSTM(hidden_dim, return_sequences = False)(embedded)\n",
    "    outputs = layers.Dense(1, activation = \"linear\")(hidden1)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer = tf.optimizers.Adam(),\n",
    "                  loss = \"mean_absolute_error\",\n",
    "                  metrics = [\"mean_absolute_error\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWZtLzduT_sH"
   },
   "source": [
    "Instantiate model and show it's architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "02bcqmcvTIDW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 300)          3000000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                42624     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3042657 (11.61 MB)\n",
      "Trainable params: 3042657 (11.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0W4SzaRqUExq"
   },
   "source": [
    "Fit model on training data and save best model to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQZ8zbxbSzZb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 17:45:11.545408: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp_10.\n",
      "2025-10-06 17:45:11.988355: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_36/output/_23'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 476s 47ms/step - loss: 11.6385 - mean_absolute_error: 11.6385 - val_loss: 2.4511 - val_mean_absolute_error: 2.4511\n",
      "Epoch 2/3\n",
      " 1592/10000 [===>..........................] - ETA: 4:26 - loss: 2.4970 - mean_absolute_error: 2.4970"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint(\"lstm.keras\", save_best_only=True)]\n",
    "\n",
    "history = model.fit(vectorized_train_ds.cache(),\n",
    "          validation_data = vectorized_val_ds.cache(),\n",
    "          epochs = 3,\n",
    "          batch_size = 128,\n",
    "          callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7NOcSDY0Y6I"
   },
   "source": [
    "Plot the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BoHl0JaJ5fJm"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['mean_absolute_error'])\n",
    "plt.plot(history.history['val_mean_absolute_error'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJ347rt_Tx0G"
   },
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKR36ArkT2Gq"
   },
   "source": [
    "Load best model from training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zA_ON4yBTb2a"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"lstm.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LRhBvwPT1q-"
   },
   "source": [
    "Make predictions on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yckI-BTWSTFm"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(vectorized_test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMFi18uLT7tG"
   },
   "source": [
    "Calculate accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afIwDkWYS_i4"
   },
   "outputs": [],
   "source": [
    "print(metrics.mean_absolute_error(test_corpus_target, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1kHkaqxz9sVdaOC2i4FJVOOFW9cCiBkYu",
     "timestamp": 1636383829898
    }
   ]
  },
  "kernelspec": {
   "display_name": "amlta2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
