{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4drq3zd0Yl6"
   },
   "source": [
    "# <font color=\"#003660\">Applied Machine Learning for Text Analysis (M.184.5331)</font>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkB8pITZ0dYo"
   },
   "source": [
    "# <font color=\"#003660\">Session 1: Introduction to Natural Language Processing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbNXbRF50d1S"
   },
   "source": [
    "# <font color=\"#003660\">Notebook 3: Train Your Own Word Embeddings</font>\n",
    "\n",
    "<center><br><img width=256 src=\"https://raw.githubusercontent.com/olivermueller/aml4ta-2021/main/resources/dag.png\"/><br></center>\n",
    "\n",
    "<p>\n",
    "<center>\n",
    "<div>\n",
    "    <font color=\"#085986\"><b>By the end of this lesson, you ...</b><br><br>\n",
    "        ... are able to train your own word embeddings from data.\n",
    "    </font>\n",
    "</div>\n",
    "</center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpXD2GY90UNN"
   },
   "source": [
    "# Import packages\n",
    "\n",
    "As always, we first need to load a number of required Python packages:\n",
    "- `pandas` provides high-performance, easy-to-use data structures and data analysis tools.\n",
    "- `spacy` offers industrial-strength natural language processing.\n",
    "- `gensim` is a fast library for training of vector embeddings and topic models.\n",
    "- `sklearn` is the de-facto standard machine learning package in Python.\n",
    "- `plotly` is a library for creating interactive plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNgYvVea0UNN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import spacy\n",
    "from gensim.models import word2vec\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpnK3Eb00UNX"
   },
   "source": [
    "# How are word embeddings learned?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiPasIBY0UNX"
   },
   "source": [
    "Word embeddings can be learned from a given corpus by training a shallow neural network. The training objective of the network is either to predict a target word from its context words in a sentence (CBOW) or, vice versa, to predict the context words of a target word in a sentence (Skip-gram). After training, the weights matrix W represents the actual embedding vectors. (Mikolov et al., 2013)\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img width=512 src=\"https://git.uni-paderborn.de/data.analytics.teaching/aml4ta-2020/-/raw/master/week_3/images/cbow_skipgram.jpg\"/>Source: Kimothi et al. (2020)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGxkqnFe0UNX"
   },
   "source": [
    "# Load documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmaWF3ER0UNX"
   },
   "source": [
    "Load wine reviews (Source: https://www.kaggle.com/datasets/zynicide/wine-reviews) from a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"https://raw.githubusercontent.com/olivermueller/amlta-2025/main/Session_01/winemag-data-130k-v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFD6jgiF0UNY"
   },
   "source": [
    "# Preprocess documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4nBClQR0UNY"
   },
   "source": [
    "Perform some standard natural language preprocessing steps with spaCy. As word embeddings are best trained on sentences, not documents, we first cut the reviews into sentences and then preprocess them sentence by sentence.\n",
    "\n",
    "Warning: This may take some minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-TLOTX50UNY",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n",
    "nlp.add_pipe('sentencizer')\n",
    "\n",
    "def spacy_sentence_tokenize(df, text_col=\"description\", batch_size=1000, n_process=4):\n",
    "    texts = (str(x) if pd.notna(x) and x else \"\" for x in df[text_col].values)\n",
    "    sentences = []\n",
    "    for doc in nlp.pipe(texts, batch_size=batch_size, n_process=n_process):\n",
    "        for sent in doc.sents:\n",
    "            toks = [t.text.lower() for t in sent if t.is_alpha]\n",
    "            if toks:\n",
    "                sentences.append(toks)\n",
    "    return sentences\n",
    "\n",
    "sentences = spacy_sentence_tokenize(corpus, text_col=\"description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwMrrusB0UNZ"
   },
   "source": [
    "How many sentences do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1667486816128,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -60
    },
    "id": "ZMk9OqVP0UNZ",
    "outputId": "389ad762-df2b-4be8-bb22-5714bc16a14f"
   },
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTzW5f3_0UNa"
   },
   "source": [
    "Look at the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1667486827557,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -60
    },
    "id": "q_QskZol0UNa",
    "outputId": "01aacc20-2bc7-457e-c586-b741da11dd59",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRjy3qYn0UNa"
   },
   "source": [
    "# Learn word embeddings from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1Nz2tVV0UNa"
   },
   "source": [
    "We use Gensim's implementation of word2vec to create word embeddings. See https://radimrehurek.com/gensim/models/keyedvectors.html#module-gensim.models.keyedvectors for documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcQEgmXF0UNa"
   },
   "source": [
    "Create a model with 300 dimensions and a context window of 6 words. Only consider words that appear at least in 2 documents. Use 6 CPU cores for estimating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QgwWepqb0UNa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(sentences, vector_size=300, window = 6, min_count = 2, workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKUV1Kd00UNa"
   },
   "source": [
    "Get word vectors from model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IgG_6jaZ0UNa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opj1RKV_0UNb"
   },
   "source": [
    "# Explore word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTqNH4C-0UNb"
   },
   "source": [
    "Retrieve most similar words to a given word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1667486940458,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -60
    },
    "id": "6C17oBpp0UNb",
    "outputId": "fa8cd4a1-b0dd-40f6-deca-af4c18698c4f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_vectors.most_similar(\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1667486968897,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -60
    },
    "id": "yCYSauoD0UNb",
    "outputId": "82f0a3aa-00e0-4443-ca30-9194adec36a3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_vectors.most_similar(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuP3ubCn0UNc"
   },
   "source": [
    "Which word doesn't belong to the set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1667486975463,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -60
    },
    "id": "fuaPa_520UNc",
    "outputId": "0986d58b-a523-4c41-aa75-7c1611749fe9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_vectors.doesnt_match([\"red\", \"raspberry\", \"cranberry\", \"peach\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1667486995836,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -60
    },
    "id": "EYRxgd5P0UNc",
    "outputId": "2607df94-e7bc-4009-afde-4033ff92aaa0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_vectors.doesnt_match([\"white\", \"cherry\", \"cantaloupe\", \"citrus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-osmaKEv0UNc"
   },
   "source": [
    "Let's look at some analogies using \"King â€“ Man + Woman = Queen\"-style vector arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdWXHwgx0UNc"
   },
   "source": [
    "Fig - Red + White = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 881,
     "status": "ok",
     "timestamp": 1667487005777,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -60
    },
    "id": "KkhETmQy0UNc",
    "outputId": "3689acf8-7418-4cab-cc73-d6a9896f0ecc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_vectors.most_similar(positive=['fig', 'white'], negative=['red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jv_8FBe30UNd"
   },
   "source": [
    "Honey - White + Red = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1667487054908,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -60
    },
    "id": "s1GD8puB0UNd",
    "outputId": "19bae8e6-f090-4314-ecc9-32fa94528f96",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_vectors.most_similar(positive=['honey', 'red'], negative=['white'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RktVMiFc0UNd"
   },
   "source": [
    "Riesling - White + Red = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1667487099584,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -60
    },
    "id": "I60IAqsX0UNd",
    "outputId": "685a754f-58ca-42e0-a1b1-2da503bfa4f2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_vectors.most_similar(positive=['riesling', 'red'], negative=['white'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_79S_bDC0UNd"
   },
   "source": [
    "# Visualize embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dx8CfMfI0UNd"
   },
   "source": [
    "Get a list of all the words in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gx6ndOIA0UNd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab = list(word_vectors.key_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezf-0WXm0UNe"
   },
   "source": [
    "Retrieve the associated word embedding vectors from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OrfDB_s40UNe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = word_vectors[vocab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNLw0kPB0UNe"
   },
   "source": [
    "Reduce the dimensionality of the data with PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Am2TOjDu0UNe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_pca = PCA(n_components=2).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_yIxxpd0UNf"
   },
   "source": [
    "Reformat data, add similarity to a \"seed\" word, (filter to most similar words), and create an interactive scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 1834,
     "status": "ok",
     "timestamp": 1667487136433,
     "user": {
      "displayName": "Oliver Mueller",
      "userId": "12717968064814035358"
     },
     "user_tz": -60
    },
    "id": "vyuCr_qh0UNf",
    "outputId": "4cb84d05-df69-470a-cf6c-d55dae113ded"
   },
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(X_pca, index=vocab, columns=['x', 'y'])\n",
    "pca_df[\"word\"] = vocab\n",
    "\n",
    "seed = \"citrus\"\n",
    "pca_df[\"sim\"] = 0\n",
    "\n",
    "for word, sim in word_vectors.most_similar(seed, topn=100):\n",
    "    pca_df.loc[word, 'sim'] = sim\n",
    "\n",
    "pca_df = pca_df[pca_df[\"sim\"]>0]\n",
    "\n",
    "fig = px.scatter(pca_df, x=\"x\", y=\"y\", color=\"sim\",\n",
    "                 hover_data=[\"word\"],\n",
    "                 opacity = 0.2, color_continuous_scale='agsunset_r')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1HhlHsqxx4kYPaCdu6NmguaXjX9-GoKJh",
     "timestamp": 1636383280879
    }
   ]
  },
  "kernelspec": {
   "display_name": "amlta2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
